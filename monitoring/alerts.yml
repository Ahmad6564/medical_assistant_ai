# Prometheus Alert Rules for Medical AI Assistant

groups:
  - name: api_alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: rate(medical_ai_errors_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors/sec for {{ $labels.error_type }}"
      
      # API latency
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(medical_ai_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High API latency detected"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.endpoint }}"
      
      # Service down
      - alert: ServiceDown
        expr: up{job="medical-ai-api"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Medical AI API is down"
          description: "The API service has been down for more than 2 minutes"
      
      # High request rate
      - alert: HighRequestRate
        expr: rate(medical_ai_requests_total[5m]) > 100
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "High request rate"
          description: "Request rate is {{ $value }} req/sec"
      
      # Rate limit exceeded frequently
      - alert: FrequentRateLimiting
        expr: rate(medical_ai_requests_total{status="429"}[5m]) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Frequent rate limiting"
          description: "Rate limiting triggered {{ $value }} times/sec"
